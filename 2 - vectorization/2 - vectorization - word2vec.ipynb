{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data frames with cleaned data from previous notebook\n",
    "\n",
    "%store -r textdata\n",
    "\n",
    "%store -r titledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import gensim \n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pre-trained word2vec model trained on Google News data\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "wv = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv.fill_norms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply word2vec to text column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test sets\n",
    "\n",
    "text_train, text_test = train_test_split(\n",
    "    textdata,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add column to dataframes containing average vector for each row's text\n",
    "\n",
    "text_train['vectors'] = text_train['text'].apply(lambda x: wv.get_mean_vector(x, ignore_missing=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test['vectors'] = text_test['text'].apply(lambda x: wv.get_mean_vector(x, ignore_missing=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7768</th>\n",
       "      <td>[swirl, revelation, allegation, russian, invol...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0003381749, 0.004170802, 8.591608e-05, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20151</th>\n",
       "      <td>[despite, problem, plague, donald, trump, fail...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0077793393, 0.019553736, 0.0042430665, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>[tune, alternate, current, radio, network, acr...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0028786482, 0.008605114, 0.0070612496, 0.03...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60898</th>\n",
       "      <td>[kiev, reuters, ukrainian, president, petro, p...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.02019227, -0.0072652902, 0.0150532145, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18689</th>\n",
       "      <td>[madman, merkel, demand, internet, publicly, r...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0044224965, 0.002993722, 0.005907909, 0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66235</th>\n",
       "      <td>[aboard, aquarius, rescue, ship, reuters, migr...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.011924975, 0.010988319, 0.0011468495, 0.025...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44512</th>\n",
       "      <td>[moscow, reuters, senior, russian, lawmaker, s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.006364392, 0.0013059269, 0.018351823, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>[trump, want, win, rust, belt, need, practice,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0034884035, 0.010201223, 0.00054162065, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17458</th>\n",
       "      <td>[dubai, reuters, former, egyptian, prime, mini...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0059219073, 0.0037472998, 0.011917742, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69180</th>\n",
       "      <td>[tim, kaine, cheer, end, white, majority, span...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.00827276, 0.0054527237, 0.01909309, 0.0335...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40987 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "7768   [swirl, revelation, allegation, russian, invol...      0   \n",
       "20151  [despite, problem, plague, donald, trump, fail...      1   \n",
       "1003   [tune, alternate, current, radio, network, acr...      1   \n",
       "60898  [kiev, reuters, ukrainian, president, petro, p...      0   \n",
       "18689  [madman, merkel, demand, internet, publicly, r...      1   \n",
       "...                                                  ...    ...   \n",
       "66235  [aboard, aquarius, rescue, ship, reuters, migr...      0   \n",
       "44512  [moscow, reuters, senior, russian, lawmaker, s...      0   \n",
       "921    [trump, want, win, rust, belt, need, practice,...      1   \n",
       "17458  [dubai, reuters, former, egyptian, prime, mini...      0   \n",
       "69180  [tim, kaine, cheer, end, white, majority, span...      1   \n",
       "\n",
       "                                                 vectors  \n",
       "7768   [-0.0003381749, 0.004170802, 8.591608e-05, 0.0...  \n",
       "20151  [0.0077793393, 0.019553736, 0.0042430665, 0.03...  \n",
       "1003   [0.0028786482, 0.008605114, 0.0070612496, 0.03...  \n",
       "60898  [-0.02019227, -0.0072652902, 0.0150532145, 0.0...  \n",
       "18689  [0.0044224965, 0.002993722, 0.005907909, 0.022...  \n",
       "...                                                  ...  \n",
       "66235  [0.011924975, 0.010988319, 0.0011468495, 0.025...  \n",
       "44512  [-0.006364392, 0.0013059269, 0.018351823, 0.01...  \n",
       "921    [0.0034884035, 0.010201223, 0.00054162065, 0.0...  \n",
       "17458  [-0.0059219073, 0.0037472998, 0.011917742, 0.0...  \n",
       "69180  [-0.00827276, 0.0054527237, 0.01909309, 0.0335...  \n",
       "\n",
       "[40987 rows x 3 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view results\n",
    "\n",
    "text_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>vectors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33113</th>\n",
       "      <td>[new, york, reuters, michael, moore, left-wing...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.00028460205, 0.0022248349, -0.0014604458, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56520</th>\n",
       "      <td>[catholic, church, decade, long, likely, even,...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.021414263, 0.006217401, 0.010361887, 0.0372...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24790</th>\n",
       "      <td>[megyn, kelly, fox, news, anchor, definitely, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.008622794, 0.010029217, -0.0054355743, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5431</th>\n",
       "      <td>[peter, certo, wordseven, election, year, shoo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.007797616, 0.005972583, 0.013798478, 0.0367...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16964</th>\n",
       "      <td>[something, interest, unz, review, recipient, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.009118676, 0.008844791, 0.008179908, 0.0458...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38902</th>\n",
       "      <td>[australia, stop, donation, corrupt, clinton, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.006731601, -0.0014126656, 0.0031150207, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48226</th>\n",
       "      <td>[ten, progressive, judge, virginia, decide, mu...</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.005291016, 0.004906544, 0.01436485, 0.02873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19398</th>\n",
       "      <td>[fort, lauderdale, fla, reuters, florida, gove...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.005333254, 0.006447841, 0.0089601865, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4343</th>\n",
       "      <td>[donald, trump, stun, neglect, disavow, nazi, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.001132972, 0.009400117, 0.009536006, 0.0369...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36825</th>\n",
       "      <td>[president, trump, nominate, christopher, wray...</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0077695693, 0.011566349, 0.008971804, 0.02...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17567 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label  \\\n",
       "33113  [new, york, reuters, michael, moore, left-wing...      0   \n",
       "56520  [catholic, church, decade, long, likely, even,...      1   \n",
       "24790  [megyn, kelly, fox, news, anchor, definitely, ...      1   \n",
       "5431   [peter, certo, wordseven, election, year, shoo...      1   \n",
       "16964  [something, interest, unz, review, recipient, ...      1   \n",
       "...                                                  ...    ...   \n",
       "38902  [australia, stop, donation, corrupt, clinton, ...      1   \n",
       "48226  [ten, progressive, judge, virginia, decide, mu...      0   \n",
       "19398  [fort, lauderdale, fla, reuters, florida, gove...      0   \n",
       "4343   [donald, trump, stun, neglect, disavow, nazi, ...      1   \n",
       "36825  [president, trump, nominate, christopher, wray...      1   \n",
       "\n",
       "                                                 vectors  \n",
       "33113  [-0.00028460205, 0.0022248349, -0.0014604458, ...  \n",
       "56520  [0.021414263, 0.006217401, 0.010361887, 0.0372...  \n",
       "24790  [0.008622794, 0.010029217, -0.0054355743, 0.02...  \n",
       "5431   [0.007797616, 0.005972583, 0.013798478, 0.0367...  \n",
       "16964  [0.009118676, 0.008844791, 0.008179908, 0.0458...  \n",
       "...                                                  ...  \n",
       "38902  [-0.006731601, -0.0014126656, 0.0031150207, 0....  \n",
       "48226  [0.005291016, 0.004906544, 0.01436485, 0.02873...  \n",
       "19398  [-0.005333254, 0.006447841, 0.0089601865, 0.02...  \n",
       "4343   [0.001132972, 0.009400117, 0.009536006, 0.0369...  \n",
       "36825  [-0.0077695693, 0.011566349, 0.008971804, 0.02...  \n",
       "\n",
       "[17567 rows x 3 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data into x and y\n",
    "\n",
    "x_text_train_wv = text_train.vectors\n",
    "x_text_test_wv = text_test.vectors\n",
    "\n",
    "y_text_train_wv = text_train.label\n",
    "y_text_test_wv = text_test.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vector arrays usable for modelling\n",
    "\n",
    "x_text_train_wv_2d = np.stack(x_text_train_wv)\n",
    "\n",
    "x_text_test_wv_2d = np.stack(x_text_test_wv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_text_train_wv_2d' (ndarray)\n",
      "Stored 'x_text_test_wv_2d' (ndarray)\n",
      "Stored 'y_text_train_wv' (Series)\n",
      "Stored 'y_text_test_wv' (Series)\n"
     ]
    }
   ],
   "source": [
    "#store variables for later use\n",
    "\n",
    "%store x_text_train_wv_2d\n",
    "%store x_text_test_wv_2d\n",
    "%store y_text_train_wv\n",
    "%store y_text_test_wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply word2vec to title column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split title data into training and test sets\n",
    "\n",
    "title_train, title_test = train_test_split(\n",
    "    titledata,\n",
    "    test_size=0.3,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_test['vectors'] = title_test['title'].apply(lambda x: wv.get_mean_vector(x, ignore_missing=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train['vectors'] = title_train['title'].apply(lambda x: wv.get_mean_vector(x, ignore_missing=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split train and test data into x and y\n",
    "\n",
    "x_title_train_wv = title_train.vectors\n",
    "x_title_test_wv = title_test.vectors\n",
    "\n",
    "y_title_train_wv = title_train.label\n",
    "y_title_test_wv = title_test.label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make vector arrays usable for modelling\n",
    "\n",
    "x_title_train_wv_2d = np.stack(x_title_train_wv)\n",
    "\n",
    "x_title_test_wv_2d = np.stack(x_title_test_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'x_title_train_wv_2d' (ndarray)\n",
      "Stored 'x_title_test_wv_2d' (ndarray)\n",
      "Stored 'y_title_train_wv' (Series)\n",
      "Stored 'y_title_test_wv' (Series)\n"
     ]
    }
   ],
   "source": [
    "#store variables for later use\n",
    "\n",
    "%store x_title_train_wv_2d\n",
    "%store x_title_test_wv_2d\n",
    "%store y_title_train_wv\n",
    "%store y_title_test_wv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
